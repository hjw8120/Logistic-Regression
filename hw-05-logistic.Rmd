---
title: "HW 05: Logistic Regression"
author: "Hannah Wang"
date: "06 November 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning=FALSE,
                      message=FALSE)
```

### Load data and packages

```{r load-packages}
library(tidyverse)
library(knitr)
library(broom)
library(pROC)
library(skimr)
library(rms)
```

```{r load-data}
mn08 <- read.csv("data/mn08.csv")
```

### Question 1
```{r odds}
odds_behind <- (18/20) / (1 - 18/20)
odds_tied <- (71/90) / (1 - 71/90)
odds_ahead <- (55/75) / (1 - 55/75)

odds_behind
odds_tied
odds_ahead
```

The odds of a successful penalty kick for games in which the goalkeeperâ€™s team was behind is 9, tied is 3.74, and ahead is 2.75.

```{r odds-ratios}
odds_behind/odds_tied
odds_tied/odds_ahead
```

The odds ratios for successful penalty kicks for behind versus tied is 2.41, and tied versus ahead is 1.36.

### Question 2
The odds of children in day care centers getting nightly cough is expected to be, on average, 1.89 times the odds of children in home care getting nightly cough. We are 95% confident that the true odds ratio lies between 1.34 and 1.67, meaning we are 95% confident that the odds of children in day care centers getting nightly cough is 1.34 to 1.67 times the odds of children in home care getting nightly cough.

The odds of children getting a blocked or runny nose without common cold in day care is expected to be, on average, 1.55 times the odds of getting it in home care. We are 95% confident that the true odds ratio lies between 1.07 and 1.61, meaning we are 95% confident that the odds of children getting a blocked or runny nose without common cold in day care is 1.07 to 1.61 times the odds of getting it in home care.

### Question 3
log-odds-hat = -1.123 + 0.018 * distance + 0.374 * morphlight - 0.028 * distance:morphlight

If a moth is dark and its distance from Liverpool is 0, the log odds of the moth being removed after 24 hours is -1.123.

Holding all else constant, as distance from Liverpool increases by 1 km, we expect the log odds of a moth being removed after 24 hours to increase by 0.018.

Holding all else constant, the difference in the log odds of a light moth being removed and the log odds of a dark moth being removed after 24 hours is 0.374.

Holding all else constant, if a moth is light, as distance from Liverpool increases by 1 km, we expect the log odds of the moth being removed after 24 hours to decrease by 0.01.

### Question 4
If a moth is dark and its distance from Liverpool is 0, the odds of the moth being removed after 24 hours is exp(-1.123) = 0.325.

Holding all else constant, as distance from Liverpool increases by 1 km, we expect the odds of a moth being removed after 24 hours to multiply by a factor of exp(0.018) = 1.02.

Holding all else constant, the odds of a light moth being removed is expected to be exp(0.374) = 1.45 times the odds of a dark moth being removed after 24 hours.

Holding all else constant, if a moth is light, as distance from Liverpool increases by 1 km, we expect the odds of a moth being removed after 24 hours to multiply by a factor of exp(-0.01) = 0.99.

### Question 5
log-odds = -1.123 + 0.018(7.2) + 0.374(0) - 0.028(0) = -0.9934

The predicted log odds of being removed for a dark moth that is glued to the trunk of a tree 7.2 km from Liverpool is -0.9934.

The predicted odds of being removed for a dark moth that is glued to the trunk of a tree 7.2 km from Liverpool is exp(-0.9934) = 0.3703.

### Question 6
log-odds = -1.123 + 0.018(41.5) + 0.374(1) - 0.028(41.5) = -1.164

The predicted probability of being removed for a light moth that is glued to the trunk of a tree 41.5 km from Liverpool is exp(-1.164)/(1+exp(-1.164)) = 0.2379.

### Question 7

#### Introduction

The objective is to fit a logistic model that can be used to predict whether the Democratic candidate will win given county in Minnesota baesd on the characteristics of that county. 

The response variable is categorical, and indicates whether or not Obama won the majority vote (1 is won, 0 is otherwise).
```{r obama-win}
mn08 <- mn08 %>%
  mutate(obama_win = case_when(pct_Obama > 50 ~ 1,
                               pct_Obama <= 50 ~ 0))
```

```{r prop}
mn08 %>%
  count(obama_win) %>%
  mutate(prop = n/sum(n))
```

Out of the 87 counties in Minnesota, Obama won the majority vote in 42 and lost in 45. He won in 0.48 of the counties and lost in 0.52 of the counties.

#### Exploratory Data Analysis
Initially, we can eliminate the variables County, Obama, McCain, pct_Obama. County is just the identifier for the the observations. Obama, McCain, and pct_Obama are the variables used to calculate the response variable (whether Obama won) so they would directly predict the response.

We will combine Obama and McCain to create a new variable `total_votes` to give us more information about the population. 
```{r totalvotes}
mn08 <- mn08 %>%
  mutate(total_votes = Obama + McCain)
```

We use the `skim` function to get a quick overview of the distribution of the remaining variables. 
```{r skim}
skim(mn08)
```

Gini_Index, medAge2007, and pct_native have 40 missing observations, so we should look into eliminating those variables (see if they have high correlations with any other predictor variables).

We created a pairs plot and correlation matrix to examine the correlation between the predictor variables and see if there are any potential multicollinearities.

```{r pairs1}
pairs(data = mn08, obama_win ~ pct_rural + medHHinc + unemp_rate + pct_poverty + medAge2007 + medAge2000 + Gini_Index + pct_native + total_votes, lower.panel = NULL)
```

```{r correlation}
mn08 %>%
  select(-obama_win, -County, -Obama, -McCain) %>%
  cor()
```

From the pairs plot and correlation matrix, we see that:

medAge2000 and medAge2007 are highly correlated, so we can eliminate medAge2007 because it has a lot of missing observations.

Gini_Index and pct_poverty are highly correlated, so we can eliminate Gini_Index because it has a lot of missing observations.

pct_rural and pct_native are highly correlated, so we can eliminate pct_native because it has a lot of missing observations.

It would be beneficial to eliminate these variables because they are potentially collinear with other predictor variables, which causes biased estimates of the regression parameters. They also have many missing observations (about half the data), which would cause problems in model fitting. 

##### Univariate Analysis
Created histograms to visualize the distribution of remaining predictor variables.
```{r histograms}
ggplot(data = mn08, mapping = aes(x = medHHinc)) + geom_histogram() + labs(title = "Distribution of Median Household Income")

ggplot(data = mn08, mapping = aes(x = unemp_rate)) + geom_histogram() + labs(title = "Distribution of Unemployment Rate")

ggplot(data = mn08, mapping = aes(x = pct_poverty)) + geom_histogram() + labs(title = "Distribution of People Living Below Poverty Line")

ggplot(data = mn08, mapping = aes(x = medAge2000)) + geom_histogram() + labs(title = "Distribution of Median Age in 2000")

ggplot(data = mn08, mapping = aes(x = total_votes)) + geom_histogram() + labs(title = "Distribution of Total Votes")
```

The distributions for median household income and unemployment rate are skewed right due to the relatively fewer counties with high income and high unemployment rate, some of which are potential outliers. The distribution for total votes is strongly skewed right due to a few cities in Minnesota that are very high outliers. The distributions for people living below poverty line and median age are relatively normally distributed.

##### Bivariate Analysis
Created box plots to visualize quantitative predictor variables vs. categorical response variable of whether or not Obama won majority vote.
```{r plots}
mn08 %>%
  group_by(obama_win) %>%
  ggplot(mapping = aes(x = factor(obama_win), y = medHHinc)) + geom_boxplot() + labs(title = "Median Household Income vs. Obama Majority Win", y = "Median Household Income", x = "Obama Majority Win")

mn08 %>%
  group_by(obama_win) %>%
  ggplot(mapping = aes(x = factor(obama_win), y = unemp_rate)) + geom_boxplot() + labs(title = "Unemployment Rate vs. Obama Majority Win", y = "Unemployment Rate", x = "Obama Majority Win")

mn08 %>%
  group_by(obama_win) %>%
  ggplot(mapping = aes(x = factor(obama_win), y = pct_poverty)) + geom_boxplot() + labs(title = "Percent below Poverty Line vs. Obama Majority Win", y = "Percent below Poverty Line", x = "Obama Majority Win")

mn08 %>%
  group_by(obama_win) %>%
  ggplot(mapping = aes(x = factor(obama_win), y = medAge2000)) + geom_boxplot() + labs(title = "Median Age in 2000 vs. Obama Majority Win", y = "Median Age in 2000", x = "Obama Majority Win")

mn08 %>%
  group_by(obama_win) %>%
  ggplot(mapping = aes(x = factor(obama_win), y = total_votes)) + geom_boxplot() + labs(title = "Total Votes vs. Obama Majority Win", y = "Total Votes", x = "Obama Majority Win")
```

From the boxplots, we see that counties where Obama won the majority vote had lower medians for median household income, unemployment rate, and total votes, but had higher medians for percent of people living below poverty line and median age in 2000. The spreads for the predictor variables (indicated by IQR) are relatively equal for all variables except median age in 2000, where median age for counties where Obama won has a much wider spread.

#### Model Fitting
```{r model}
full_model <- glm(obama_win ~ pct_rural + medHHinc + unemp_rate + pct_poverty + medAge2000 + total_votes, data = mn08, family = binomial)
kable(tidy(full_model,conf.int=TRUE),digits=5)
```

obama_win-hat = -7.07635 + 0.00816 * pct_rural + 0.00003 * medHHinc -0.36483 * unemp_rate + 0.24723 * pct_poverty + 0.11598 * medAge2000 + 0.00001 * total_votes

```{r backward}
regfit_backward <- step(full_model, direction = "backward")
```

We conduct backwards selection using AIC to select the model with the lowest AIC. In this case, since the number of predictor variables is not greater than 8, using BIC (which penalizes for n>8 to favor more parsimonious models) would not make much of a difference. This final model includes the predictor variables medAge2000, unemp_rate, total_votes, and pct_poverty.

```{r final-model}
final_model <- glm(obama_win ~ medAge2000 + unemp_rate + total_votes + pct_poverty, data = mn08)
kable(tidy(final_model,conf.int=TRUE),digits=5)
```

obama_win-hat = -0.35044 + 0.02176 * medAge2000 - 0.0719 * unemp_rate + 	0.000001 * total_votes + 0.03892 * pct_poverty

#### Model Assessment
We look at the variance inflation factor (VIF) to detect multicollinearity. None of the VIFs are greater than 10, so we do not have multicollinearity in the final model. 
```{r vif}
tidy(vif(final_model))
```

```{r augment}
model_aug <- augment(final_model)
```

```{r binned-resid}
arm::binnedplot(x = model_aug$.fitted,
                y=model_aug$.resid,
                xlab="Predicted Probabilities",
                main = "Binned Residuals vs. Predicted Probabilities",
                col.int = FALSE)
```

```{r medage-resid}
arm::binnedplot(x = model_aug$medAge2000,
                y = model_aug$.resid,
                xlab= "Median Age in 2000",
                main = "Binned Residuals vs. Median Age in 2000",
                col.int = FALSE)
```

```{r unemp-resid}
arm::binnedplot(x = model_aug$unemp_rate,
                y = model_aug$.resid,
                xlab= "Unemployment Rate",
                main = "Binned Residuals vs. Unemployment Rate",
                col.int = FALSE)
```

```{r votes-resid}
arm::binnedplot(x = model_aug$total_votes,
                y = model_aug$.resid,
                xlab= "Total Votes",
                main = "Binned Residuals vs. Total Votes",
                col.int = FALSE)
```

```{r poverty-resid}
arm::binnedplot(x = model_aug$pct_poverty,
                y = model_aug$.resid,
                xlab= "Percent Below Poverty Line",
                main = "Binned Residuals vs. Poverty Rate",
                col.int = FALSE)
```

The binned residuals vs. predicted probabilities and binned residuals vs. medAge2000, unemp_rate, and pct_poverty are randomly scattered around 0 and have small magnitudes close to 0 so they do not violate linearity. The binned residuals vs. total_votes has a high outlier which could be evaluated in further studies. However, overall, the final model does not violate any assumptions, making it an appropriate fit for the data.

#### Analysis
```{r roc}
library(plotROC)
roccurve <- ggplot(model_aug, aes(d = as.numeric(obama_win), m = .fitted)) +
geom_roc(n.cuts = 5, labelround = 3) + geom_abline(intercept = 0) + labs(title = "ROC Curve")
roccurve
```

```{r auc}
calc_auc(roccurve)$AUC
```

The area under the ROC curve indicates how likely you are able to differentiate between trues and falses (predicting a win correctly vs. predicting a win incorrectly). A logistic model fits well if the AUC is close to 1. For predicting situations as complex as political elections, 0.68 is a relatively high proportion, showing the model decently differentiates between predicting wins.

From the model, we decide on a threshold probability of 0.503, with a false positive rate (incorrectly predict Obama's win) of 0.4 and a true positive rate (correctly predict Obama's win) of 0.6 because this is the point on the ROC curve closest to the top left corner (true positive rate of 1) where all wins for Obama are predicted correctly.

In the 2020 election, if the predicted probability of the Democratic candidate winning in a county is above the threshold of 0.503, the candidate should allocate resources to trying to win that county. However, if the predicted probability of the Democratic candidate winning in a county is below 0.503, the candidate should allocate little to no resources since they are not likely to win the majority vote.

### Overall

